{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline: 2 Anos, Features Básicas ---\n",
      "Dados não foram baixados. Execute download_data() primeiro.\n",
      "Dados não processados. Execute preprocess_and_engineer_features() primeiro.\n",
      "Modelo RandomForest não encontrado para otimização.\n",
      "\n",
      "Gerando relatório de avaliação...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Modelo', 'Acurácia', 'Precisão (Alta)', 'Recall (Alta)',\\n       'F1-Score (Alta)', 'Precisão (Baixa)', 'Recall (Baixa)',\\n       'F1-Score (Baixa)'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 314\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Pipeline: 2 Anos, Features Básicas ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    313\u001b[39m pipeline_basic = FinancialModelPipeline(years_of_data=\u001b[32m2\u001b[39m, advanced_features=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[43mpipeline_basic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimize_rf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m pipeline_basic.save_models(\u001b[33m'\u001b[39m\u001b[33mmodels_basic_2years\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    317\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Pipeline: 5 Anos, Features Avançadas ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 300\u001b[39m, in \u001b[36mFinancialModelPipeline.run_pipeline\u001b[39m\u001b[34m(self, optimize_rf, optimize_xgb)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimize_xgb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.advanced_features:\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimize_model(\u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_evaluation_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 282\u001b[39m, in \u001b[36mFinancialModelPipeline.generate_evaluation_report\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    280\u001b[39m     all_results.append(\u001b[38;5;28mself\u001b[39m.results[model_name])\n\u001b[32m    281\u001b[39m results_df = pd.DataFrame(all_results)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m markdown_report = \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mModelo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAcurácia\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPrecisão (Alta)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRecall (Alta)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mF1-Score (Alta)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m                              \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPrecisão (Baixa)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRecall (Baixa)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mF1-Score (Baixa)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.to_markdown(index=\u001b[38;5;28;01mFalse\u001b[39;00m, floatfmt=\u001b[33m\"\u001b[39m\u001b[33m.4f\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    285\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[33m# Relatório de Avaliação dos Modelos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vinic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Modelo', 'Acurácia', 'Precisão (Alta)', 'Recall (Alta)',\\n       'F1-Score (Alta)', 'Precisão (Baixa)', 'Recall (Baixa)',\\n       'F1-Score (Baixa)'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Funções Auxiliares para Engenharia de Atributos Avançada ---\n",
    "\n",
    "def calculate_rsi(prices, period=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    return macd\n",
    "\n",
    "def calculate_adx(df_ohlc, period=14):\n",
    "    high = df_ohlc['High']\n",
    "    low = df_ohlc['Low']\n",
    "    close = df_ohlc['Close']\n",
    "    \n",
    "    plus_dm = high.diff()\n",
    "    minus_dm = -low.diff()\n",
    "    plus_dm[plus_dm < 0] = 0\n",
    "    minus_dm[minus_dm < 0] = 0\n",
    "    \n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    \n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr)\n",
    "    minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr)\n",
    "    \n",
    "    dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)\n",
    "    adx = dx.rolling(window=period).mean()\n",
    "    return adx\n",
    "\n",
    "# --- Classe Principal da Pipeline ---\n",
    "\n",
    "class FinancialModelPipeline:\n",
    "    def __init__(self, ticker=\"^BVSP\", years_of_data=2, test_size=30, advanced_features=False):\n",
    "        self.ticker = ticker\n",
    "        self.years_of_data = years_of_data\n",
    "        self.test_size = test_size\n",
    "        self.advanced_features = advanced_features\n",
    "        self.df = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.predictions = {}\n",
    "        self.results = {}\n",
    "\n",
    "    # --- Download de dados ---\n",
    "    def download_data(self):\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        start_date = (datetime.now() - timedelta(days=self.years_of_data * 365)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        print(f\"Baixando dados do {self.ticker} de {start_date} até {end_date} ({self.years_of_data} anos)...\")\n",
    "        try:\n",
    "            data = yf.download(self.ticker, start=start_date, end=end_date)\n",
    "            self.df = data\n",
    "            print(f\"Dados baixados com sucesso. Total de {len(self.df)} linhas.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao baixar os dados: {e}\")\n",
    "            exit()\n",
    "\n",
    "    # --- Pré-processamento e engenharia de atributos ---\n",
    "    def preprocess_and_engineer_features(self):\n",
    "        if self.df is None:\n",
    "            print(\"Dados não foram baixados. Execute download_data() primeiro.\")\n",
    "            return\n",
    "\n",
    "        if 'Adj Close' in self.df.columns:\n",
    "            self.df = self.df.drop(columns=['Adj Close'])\n",
    "        self.df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "        # Target Variable\n",
    "        self.df['Next_Close'] = self.df['Close'].shift(-1)\n",
    "        self.df['Target'] = (self.df['Next_Close'] > self.df['Close']).astype(int)\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "        # Basic Features\n",
    "        self.df['Daily_Return'] = self.df['Close'].pct_change() * 100\n",
    "        self.df['SMA_5'] = self.df['Close'].rolling(window=5).mean()\n",
    "        self.df['SMA_20'] = self.df['Close'].rolling(window=20).mean()\n",
    "        self.df['Vol_20'] = self.df['Close'].rolling(window=20).std()\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            self.df[f'Close_Lag_{i}'] = self.df['Close'].shift(i)\n",
    "        \n",
    "        if self.advanced_features:\n",
    "            print(\"Aplicando engenharia de atributos avançada...\")\n",
    "            self.df['SMA_50'] = self.df['Close'].rolling(window=50).mean()\n",
    "            self.df['Vol_50'] = self.df['Close'].rolling(window=50).std()\n",
    "\n",
    "            for i in range(6, 11):\n",
    "                self.df[f'Close_Lag_{i}'] = self.df['Close'].shift(i)\n",
    "            for i in range(1, 11):\n",
    "                self.df[f'Return_Lag_{i}'] = self.df['Daily_Return'].shift(i)\n",
    "\n",
    "            self.df['RSI_14'] = calculate_rsi(self.df['Close'], 14)\n",
    "            self.df['MACD'] = calculate_macd(self.df['Close'])\n",
    "            self.df['Momentum_10'] = self.df['Close'].diff(10)\n",
    "            self.df['High_Low_Ratio'] = (self.df['High'] - self.df['Low']) / self.df['Close']\n",
    "            self.df['Close_Open_Ratio'] = (self.df['Close'] - self.df['Open']) / self.df['Open']\n",
    "            self.df['Volume_MA_Ratio'] = self.df['Volume'] / self.df['Volume'].rolling(window=20).mean()\n",
    "            self.df['Trend_5'] = (self.df['Close'] - self.df['SMA_5']) / self.df['SMA_5'] * 100\n",
    "            self.df['Trend_20'] = (self.df['Close'] - self.df['SMA_20']) / self.df['SMA_20'] * 100\n",
    "            self.df['Trend_50'] = (self.df['Close'] - self.df['SMA_50']) / self.df['SMA_50'] * 100\n",
    "            self.df['HV_5'] = self.df['Daily_Return'].rolling(window=5).std()\n",
    "            self.df['HV_20'] = self.df['Daily_Return'].rolling(window=20).std()\n",
    "            self.df['HV_50'] = self.df['Daily_Return'].rolling(window=50).std()\n",
    "            self.df['ADX_14'] = calculate_adx(self.df.copy(), 14)\n",
    "\n",
    "        self.df = self.df.dropna()\n",
    "\n",
    "        features = [col for col in self.df.columns if col not in ['Open', 'High', 'Low', 'Close', 'Next_Close', 'Target']]\n",
    "        X = self.df[features]\n",
    "        y = self.df['Target']\n",
    "\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        X = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "        self.X_train = X.iloc[:-self.test_size]\n",
    "        self.X_test = X.iloc[-self.test_size:]\n",
    "        self.y_train = y.iloc[:-self.test_size]\n",
    "        self.y_test = y.iloc[-self.test_size:]\n",
    "\n",
    "        print(f\"Pré-processamento e engenharia de atributos concluídos.\")\n",
    "        print(f\"Tamanho do conjunto de treino: {len(self.X_train)}, teste: {len(self.X_test)}\")\n",
    "        print(f\"Features utilizadas: {len(features)}\")\n",
    "\n",
    "    # --- Treinamento dos modelos ---\n",
    "    def train_models(self):\n",
    "        if self.X_train is None:\n",
    "            print(\"Dados não processados. Execute preprocess_and_engineer_features() primeiro.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nTreinando modelos...\")\n",
    "\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced')\n",
    "        rf_model.fit(self.X_train, self.y_train)\n",
    "        self.models['RandomForest'] = rf_model\n",
    "        self.predictions['RandomForest'] = rf_model.predict(self.X_test)\n",
    "\n",
    "        lr_model = LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear')\n",
    "        lr_model.fit(self.X_train, self.y_train)\n",
    "        self.models['LogisticRegression'] = lr_model\n",
    "        self.predictions['LogisticRegression'] = lr_model.predict(self.X_test)\n",
    "\n",
    "        if self.advanced_features:\n",
    "            # Modelos avançados\n",
    "            xgb_model = xgb.XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                                          subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "                                          scale_pos_weight=1, verbosity=0)\n",
    "            xgb_model.fit(self.X_train, self.y_train)\n",
    "            self.models['XGBoost'] = xgb_model\n",
    "            self.predictions['XGBoost'] = xgb_model.predict(self.X_test)\n",
    "\n",
    "            lgb_model = lgb.LGBMClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                                           num_leaves=31, subsample=0.8, colsample_bytree=0.8,\n",
    "                                           random_state=42, verbose=-1)\n",
    "            lgb_model.fit(self.X_train, self.y_train)\n",
    "            self.models['LightGBM'] = lgb_model\n",
    "            self.predictions['LightGBM'] = lgb_model.predict(self.X_test)\n",
    "\n",
    "            cat_model = CatBoostClassifier(iterations=200, depth=5, learning_rate=0.1,\n",
    "                                           subsample=0.8, verbose=0, random_state=42)\n",
    "            cat_model.fit(self.X_train, self.y_train, verbose=False)\n",
    "            self.models['CatBoost'] = cat_model\n",
    "            self.predictions['CatBoost'] = cat_model.predict(self.X_test)\n",
    "\n",
    "            gb_model = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                                                  subsample=0.8, random_state=42)\n",
    "            gb_model.fit(self.X_train, self.y_train)\n",
    "            self.models['GradientBoosting'] = gb_model\n",
    "            self.predictions['GradientBoosting'] = gb_model.predict(self.X_test)\n",
    "\n",
    "            ada_model = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "            ada_model.fit(self.X_train, self.y_train)\n",
    "            self.models['AdaBoost'] = ada_model\n",
    "            self.predictions['AdaBoost'] = ada_model.predict(self.X_test)\n",
    "\n",
    "            svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
    "            svm_model.fit(self.X_train, self.y_train)\n",
    "            self.models['SVM'] = svm_model\n",
    "            self.predictions['SVM'] = svm_model.predict(self.X_test)\n",
    "\n",
    "            knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn_model.fit(self.X_train, self.y_train)\n",
    "            self.models['KNN'] = knn_model\n",
    "            self.predictions['KNN'] = knn_model.predict(self.X_test)\n",
    "\n",
    "            estimators = [('xgb', xgb_model), ('lgb', lgb_model), ('cat', cat_model),\n",
    "                          ('gb', gb_model), ('rf', rf_model)]\n",
    "            voting_model = VotingClassifier(estimators=estimators, voting='soft', n_jobs=-1)\n",
    "            voting_model.fit(self.X_train, self.y_train)\n",
    "            self.models['Ensemble Voting'] = voting_model\n",
    "            self.predictions['Ensemble Voting'] = voting_model.predict(self.X_test)\n",
    "\n",
    "        print(\"Modelos treinados.\")\n",
    "\n",
    "    # --- Otimização de modelo ---\n",
    "    def optimize_model(self, model_name='RandomForest'):\n",
    "        if model_name not in self.models:\n",
    "            print(f\"Modelo {model_name} não encontrado para otimização.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nOtimização de hiperparâmetros para {model_name}...\")\n",
    "\n",
    "        if model_name == 'RandomForest':\n",
    "            param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15],\n",
    "                          'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4],\n",
    "                          'class_weight': ['balanced']}\n",
    "            estimator = RandomForestClassifier(random_state=42)\n",
    "        elif model_name == 'XGBoost':\n",
    "            param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7],\n",
    "                          'learning_rate': [0.01, 0.1, 0.2], 'subsample': [0.7, 0.8, 0.9],\n",
    "                          'colsample_bytree': [0.7, 0.8, 0.9]}\n",
    "            estimator = xgb.XGBClassifier(random_state=42, scale_pos_weight=1, verbosity=0)\n",
    "        else:\n",
    "            print(f\"Otimização para {model_name} não implementada.\")\n",
    "            return\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid,\n",
    "                                   scoring='accuracy', cv=3, verbose=0, n_jobs=-1)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        self.models[f'{model_name}_Optimized'] = best_model\n",
    "        self.predictions[f'{model_name}_Optimized'] = best_model.predict(self.X_test)\n",
    "        self.results[f'{model_name}_Optimized'] = self.evaluate_model(f'{model_name}_Optimized')\n",
    "\n",
    "        print(f\"Otimização concluída para {model_name}.\")\n",
    "        print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "        print(f\"Acurácia no teste: {self.results[f'{model_name}_Optimized']['Acurácia']:.4f}\")\n",
    "\n",
    "    # --- Avaliação de modelos ---\n",
    "    def evaluate_model(self, model_name):\n",
    "        if model_name not in self.models:\n",
    "            print(f\"Modelo {model_name} não encontrado para avaliação.\")\n",
    "            return None\n",
    "\n",
    "        y_pred = self.predictions[model_name]\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        report = classification_report(self.y_test, y_pred, target_names=['Baixa (0)', 'Alta (1)'], output_dict=True)\n",
    "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            \"Modelo\": model_name,\n",
    "            \"Acurácia\": accuracy,\n",
    "            \"Precisão (Alta)\": report['Alta (1)']['precision'],\n",
    "            \"Recall (Alta)\": report['Alta (1)']['recall'],\n",
    "            \"F1-Score (Alta)\": report['Alta (1)']['f1-score'],\n",
    "            \"Precisão (Baixa)\": report['Baixa (0)']['precision'],\n",
    "            \"Recall (Baixa)\": report['Baixa (0)']['recall'],\n",
    "            \"F1-Score (Baixa)\": report['Baixa (0)']['f1-score'],\n",
    "            \"Matriz de Confusão\": conf_matrix.tolist()\n",
    "        }\n",
    "\n",
    "    # --- Geração de relatório ---\n",
    "    def generate_evaluation_report(self, filename='model_evaluation_report.md'):\n",
    "        print(\"\\nGerando relatório de avaliação...\")\n",
    "        all_results = []\n",
    "        for model_name in self.models:\n",
    "            if model_name not in self.results:\n",
    "                self.results[model_name] = self.evaluate_model(model_name)\n",
    "            all_results.append(self.results[model_name])\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        markdown_report = results_df[['Modelo','Acurácia','Precisão (Alta)','Recall (Alta)','F1-Score (Alta)',\n",
    "                                      'Precisão (Baixa)','Recall (Baixa)','F1-Score (Baixa)']].to_markdown(index=False, floatfmt=\".4f\")\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"# Relatório de Avaliação dos Modelos\\n\\n\")\n",
    "            f.write(markdown_report)\n",
    "        print(f\"Relatório salvo em {filename}\")\n",
    "\n",
    "    # --- Pipeline completa ---\n",
    "    def run_pipeline(self, optimize_rf=False, optimize_xgb=False):\n",
    "        self.download_data()\n",
    "        self.preprocess_and_engineer_features()\n",
    "        self.train_models()\n",
    "        \n",
    "        if optimize_rf:\n",
    "            self.optimize_model('RandomForest')\n",
    "        if optimize_xgb and self.advanced_features:\n",
    "            self.optimize_model('XGBoost')\n",
    "\n",
    "        self.generate_evaluation_report()\n",
    "\n",
    "    # --- NOVO: salvar modelos --- \n",
    "    def save_models(self, path='.'):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for name, model in self.models.items():\n",
    "            joblib.dump(model, f'{path}/{name.replace(\" \", \"_\").lower()}_model.pkl')\n",
    "        print(f\"Modelos salvos em {path}\")\n",
    "\n",
    "\n",
    "# --- Execução ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Pipeline: 2 Anos, Features Básicas ---\")\n",
    "    pipeline_basic = FinancialModelPipeline(years_of_data=2, advanced_features=False)\n",
    "    pipeline_basic.run_pipeline(optimize_rf=True)\n",
    "    pipeline_basic.save_models('models_basic_2years')\n",
    "\n",
    "    print(\"\\n--- Pipeline: 5 Anos, Features Avançadas ---\")\n",
    "    pipeline_advanced = FinancialModelPipeline(years_of_data=5, advanced_features=True)\n",
    "    pipeline_advanced.run_pipeline(optimize_rf=True, optimize_xgb=True)\n",
    "    pipeline_advanced.save_models('models_advanced_5years')\n",
    "\n",
    "    print(\"\\n--- Execução concluída ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
